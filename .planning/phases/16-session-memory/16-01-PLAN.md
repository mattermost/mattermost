---
phase: 16-session-memory
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - plugins/langchain-agent/plugin.py
autonomous: true

must_haves:
  truths:
    - "Bot responds in a thread (root_id set on response)"
    - "Bot remembers previous messages in thread"
    - "User can have multi-turn conversations"
    - "Each thread is an independent conversation"
  artifacts:
    - path: "plugins/langchain-agent/plugin.py"
      provides: "Threading and conversation history"
      contains: "get_post_thread"
  key_links:
    - from: "plugins/langchain-agent/plugin.py (_send_response)"
      to: "Post.root_id"
      via: "Setting root_id when creating response post"
      pattern: "root_id=.*root_id"
    - from: "plugins/langchain-agent/plugin.py (handlers)"
      to: "self.api.get_post_thread"
      via: "Fetching thread history before LLM invocation"
      pattern: "get_post_thread"
    - from: "plugins/langchain-agent/plugin.py (history builder)"
      to: "AIMessage"
      via: "Converting bot posts to AIMessage"
      pattern: "AIMessage"
---

<objective>
Add threading and conversation history to the LangChain Agent plugin.

Purpose: Enable multi-turn conversations by using Mattermost threads as conversation history. Bot responses always create/continue a thread, and all messages in the thread are included as context when invoking the LLM.

Output: Modified plugin.py with threading responses and conversation history building.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16-session-memory/16-CONTEXT.md
@.planning/phases/15-langchain-core/15-01-SUMMARY.md

# Source files
@plugins/langchain-agent/plugin.py
@python-sdk/src/mattermost_plugin/_internal/mixins/posts.py
@python-sdk/src/mattermost_plugin/_internal/wrappers.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add threading to _send_response</name>
  <files>plugins/langchain-agent/plugin.py</files>
  <action>
Modify `_send_response` to accept an optional `root_id` parameter and set it on the Post:

1. Change signature from `_send_response(self, channel_id: str, message: str)` to `_send_response(self, channel_id: str, message: str, root_id: str = "")`.

2. When creating the Post, include `root_id=root_id`:
   ```python
   response = Post(id="", channel_id=channel_id, message=message, root_id=root_id)
   ```

3. Update `_send_error_response` similarly to pass through root_id:
   - Change signature to accept `root_id: str = ""`
   - Pass root_id to `_send_response`

4. Update handler calls to pass root_id:
   - Determine root_id from incoming post:
     - If `post.root_id` is non-empty: use `post.root_id` (message is in existing thread)
     - If `post.root_id` is empty: use `post.id` (new conversation, user's message becomes root)
   - Pass this root_id to `_send_response` and `_send_error_response`
  </action>
  <verify>
Check that `_send_response` signature includes `root_id` parameter and Post creation uses it:
```bash
grep -A5 "def _send_response" plugins/langchain-agent/plugin.py | grep "root_id"
```
  </verify>
  <done>All bot responses include root_id to create threads. First message in conversation becomes thread root, subsequent messages continue the thread.</done>
</task>

<task type="auto">
  <name>Task 2: Build conversation history from thread</name>
  <files>plugins/langchain-agent/plugin.py</files>
  <action>
Create a helper method to build LangChain message history from a Mattermost thread:

1. Import `AIMessage` from `langchain_core.messages` (add to existing import line 21):
   ```python
   from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
   ```

2. Add a new method `_build_conversation_history(self, post: Post, bot_id: str, system_prompt: str) -> list`:
   ```python
   def _build_conversation_history(self, post: Post, bot_id: str, system_prompt: str) -> list:
       """
       Build LangChain message history from Mattermost thread.
       
       Args:
           post: The current post being processed.
           bot_id: The bot's user ID (to distinguish bot messages).
           system_prompt: The system prompt to prepend.
       
       Returns:
           List of LangChain messages (SystemMessage, HumanMessage, AIMessage).
       """
       messages = [SystemMessage(content=system_prompt)]
       
       # Determine if this is part of an existing thread
       if post.root_id:
           # Message is in existing thread - fetch full thread
           try:
               thread = self.api.get_post_thread(post.root_id)
               # Sort posts by order (chronological)
               for post_id in thread.order:
                   thread_post = thread.posts.get(post_id)
                   if thread_post is None:
                       continue
                   # Skip the root post if it's a system message or empty
                   if not thread_post.message:
                       continue
                   # Convert to appropriate LangChain message type
                   if thread_post.user_id == bot_id:
                       messages.append(AIMessage(content=thread_post.message))
                   else:
                       messages.append(HumanMessage(content=thread_post.message))
           except Exception as e:
               self.logger.warning(f"Failed to fetch thread history: {e}")
               # Fall back to just the current message
               messages.append(HumanMessage(content=post.message))
       else:
           # New conversation - just use current message
           messages.append(HumanMessage(content=post.message))
       
       return messages
   ```

3. Ensure the current post is included:
   - If post.root_id exists: The current post is already in the thread (fetched via get_post_thread), so it's included in the loop
   - If post.root_id is empty: Current message added directly
  </action>
  <verify>
Verify the helper method exists and imports AIMessage:
```bash
grep "AIMessage" plugins/langchain-agent/plugin.py
grep "def _build_conversation_history" plugins/langchain-agent/plugin.py
```
  </verify>
  <done>Helper method converts Mattermost thread posts to LangChain message format (HumanMessage for user, AIMessage for bot).</done>
</task>

<task type="auto">
  <name>Task 3: Update handlers to use conversation history</name>
  <files>plugins/langchain-agent/plugin.py</files>
  <action>
Replace hardcoded single-message lists in handlers with conversation history:

1. In `_handle_openai_message`:
   - Replace the manual `messages = [...]` list with call to `_build_conversation_history`
   - Determine root_id for response
   - Pass root_id to response methods
   
   ```python
   def _handle_openai_message(self, post: Post) -> None:
       """Handle a message directed to the OpenAI bot using LangChain."""
       self.logger.info(f"OpenAI Agent processing message: {post.message[:50]}...")
       
       # Determine root_id for threading
       root_id = post.root_id if post.root_id else post.id

       if self.openai_model is None:
           self._send_error_response(
               post.channel_id, "OpenAI not configured. Check OPENAI_API_KEY.", root_id
           )
           return

       # Build conversation history from thread
       messages = self._build_conversation_history(
           post,
           self.openai_bot_id,
           "You are a helpful AI assistant powered by OpenAI. Be concise and helpful."
       )

       try:
           response = self.openai_model.invoke(messages)
           self._send_response(post.channel_id, response.content, root_id)
           self.logger.debug("OpenAI Agent sent response")
       except Exception as e:
           self.logger.error(f"OpenAI API error: {e}")
           self._send_error_response(post.channel_id, f"OpenAI error: {e}", root_id)
   ```

2. In `_handle_anthropic_message`:
   - Same pattern as OpenAI handler
   - Use `self.anthropic_bot_id` when calling `_build_conversation_history`
   
   ```python
   def _handle_anthropic_message(self, post: Post) -> None:
       """Handle a message directed to the Anthropic bot using LangChain."""
       self.logger.info(f"Anthropic Agent processing message: {post.message[:50]}...")
       
       # Determine root_id for threading
       root_id = post.root_id if post.root_id else post.id

       if self.anthropic_model is None:
           self._send_error_response(
               post.channel_id, "Anthropic not configured. Check ANTHROPIC_API_KEY.", root_id
           )
           return

       # Build conversation history from thread
       messages = self._build_conversation_history(
           post,
           self.anthropic_bot_id,
           "You are a helpful AI assistant powered by Anthropic Claude. Be concise and helpful."
       )

       try:
           response = self.anthropic_model.invoke(messages)
           self._send_response(post.channel_id, response.content, root_id)
           self.logger.debug("Anthropic Agent sent response")
       except Exception as e:
           self.logger.error(f"Anthropic API error: {e}")
           self._send_error_response(post.channel_id, f"Anthropic error: {e}", root_id)
   ```
  </action>
  <verify>
Test by deploying and having a multi-turn conversation with the bot:
1. Send a message to either bot
2. The response should appear as a threaded reply
3. Reply in the thread
4. The bot should remember the previous context
  </verify>
  <done>
Both handlers:
- Build conversation history from thread
- Thread their responses (root_id set)
- Remember previous messages in conversation
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **Threading verification:**
   - Send "Hello" to OpenAI bot
   - Response appears as thread reply (not separate message)
   - Click into thread to see conversation view

2. **Memory verification:**
   - In the thread, ask "What did I just say?"
   - Bot should reference the previous message

3. **Independent threads verification:**
   - Start a new conversation (outside any thread)
   - Bot should not remember previous thread's context

4. **Code verification:**
   ```bash
   # Check threading in response
   grep -A10 "def _send_response" plugins/langchain-agent/plugin.py
   
   # Check history building
   grep -A30 "def _build_conversation_history" plugins/langchain-agent/plugin.py
   
   # Check AIMessage import
   grep "from langchain_core.messages" plugins/langchain-agent/plugin.py
   ```
</verification>

<success_criteria>
- Bot responses always create/continue threads (root_id set)
- Conversation history includes all messages in thread
- User posts become HumanMessage, bot posts become AIMessage
- Multi-turn conversations work (bot remembers context)
- Independent threads have independent contexts
</success_criteria>

<output>
After completion, create `.planning/phases/16-session-memory/16-01-SUMMARY.md`
</output>
