---
phase: 18-agentic-loop
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - plugins/langchain-agent/plugin.py
  - plugins/langchain-agent/requirements.txt
autonomous: true

must_haves:
  truths:
    - "Agent retries failed tool calls up to 2 times before giving up"
    - "Agent stops after maximum 10 model calls to prevent infinite loops"
    - "Anthropic agent uses extended thinking for complex reasoning"
    - "Tool errors return informative messages instead of crashing the agent"
  artifacts:
    - path: "plugins/langchain-agent/plugin.py"
      provides: "Enhanced agentic loop with middleware"
      contains: "ToolRetryMiddleware"
    - path: "plugins/langchain-agent/plugin.py"
      provides: "Extended thinking for Anthropic"
      contains: "thinking"
    - path: "plugins/langchain-agent/requirements.txt"
      provides: "Updated dependencies"
      contains: "langchain>=1.2.0"
  key_links:
    - from: "plugins/langchain-agent/plugin.py"
      to: "langchain.agents"
      via: "create_agent import and middleware configuration"
      pattern: "create_agent|ToolRetryMiddleware|ModelCallLimitMiddleware"
---

<objective>
Enhance the LangChain agent with robust tool orchestration via middleware, add extended thinking for complex reasoning, and implement graceful tool error handling.

Purpose: Transform the basic ReAct agent into a production-quality agentic loop with retry logic, iteration limits, and thoughtful error handling - demonstrating LangChain's middleware capabilities.

Output: Enhanced `plugin.py` with middleware-based agent creation, extended thinking for Anthropic, and graceful tool error handling.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-agentic-loop/18-RESEARCH.md

# Current implementation to enhance
@plugins/langchain-agent/plugin.py
@plugins/langchain-agent/requirements.txt
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add middleware-based agent creation</name>
  <files>plugins/langchain-agent/plugin.py</files>
  <action>
Replace `create_react_agent` with `create_agent` from `langchain.agents` and add middleware for robust tool orchestration.

1. Update imports at top of file:
   - Add: `from langchain.agents import create_agent`
   - Add: `from langchain.agents.middleware import ToolRetryMiddleware, ModelCallLimitMiddleware`
   - Keep: existing imports (don't remove `create_react_agent` yet - may be used as fallback)

2. Modify `_handle_message_async` method to use `create_agent` with middleware:
   - Replace the `create_react_agent(model, tools)` call with:
     ```python
     agent = create_agent(
         model,
         tools=tools,
         system_prompt=system_prompt,
         middleware=[
             ToolRetryMiddleware(max_retries=2, backoff_factor=2.0),
             ModelCallLimitMiddleware(run_limit=10),
         ],
     )
     ```
   - This adds automatic retry for tool failures (2 retries with exponential backoff)
   - This prevents infinite loops (max 10 model calls per invocation)

3. Keep the existing fallback logic for when MCP client is unavailable - this is good defensive coding.

Note: The `create_agent` API accepts `system_prompt` directly, so we can pass it there instead of building it into messages. However, keep the conversation history building since we still need HumanMessage/AIMessage for multi-turn conversations.
  </action>
  <verify>
Python syntax check: `python -m py_compile plugins/langchain-agent/plugin.py`
Imports resolve: `cd plugins/langchain-agent && python -c "from langchain.agents import create_agent; from langchain.agents.middleware import ToolRetryMiddleware, ModelCallLimitMiddleware; print('OK')"`
  </verify>
  <done>
Agent creation uses `create_agent` with `ToolRetryMiddleware` (max_retries=2) and `ModelCallLimitMiddleware` (run_limit=10)
  </done>
</task>

<task type="auto">
  <name>Task 2: Enable extended thinking for Anthropic model</name>
  <files>plugins/langchain-agent/plugin.py</files>
  <action>
Configure Anthropic's extended thinking capability for complex reasoning tasks.

1. Modify Anthropic model initialization in `on_activate`:
   - Change the `ChatAnthropic` initialization to include thinking parameter:
     ```python
     self.anthropic_model = ChatAnthropic(
         model="claude-sonnet-4-5-20250929",
         temperature=0.7,
         max_tokens=5000,  # Increased to accommodate thinking + response
         thinking={"type": "enabled", "budget_tokens": 2000},
     )
     ```
   - `budget_tokens=2000` caps the thinking tokens to prevent excessive usage
   - `max_tokens=5000` allows for both thinking (2000) and response (3000)

2. Update the Anthropic system prompt in `_handle_anthropic_message` to leverage thinking:
   - Change to: "You are a thoughtful AI assistant powered by Anthropic Claude. Think through complex problems carefully before responding. Be concise and helpful."

This enables Claude to show its reasoning process for complex queries while keeping responses focused.
  </action>
  <verify>
Python syntax check: `python -m py_compile plugins/langchain-agent/plugin.py`
Check thinking config: `grep -n "thinking" plugins/langchain-agent/plugin.py`
  </verify>
  <done>
Anthropic model initialized with `thinking={"type": "enabled", "budget_tokens": 2000}` and `max_tokens=5000`
  </done>
</task>

<task type="auto">
  <name>Task 3: Add graceful tool error handling</name>
  <files>plugins/langchain-agent/plugin.py</files>
  <action>
Implement custom tool error handler using `@wrap_tool_call` for graceful degradation.

1. Add imports at top of file:
   - Add: `from langchain.agents.middleware import wrap_tool_call`
   - Add: `from langchain.messages import ToolMessage`

2. Add a module-level error handler function BEFORE the class definition:
   ```python
   @wrap_tool_call
   def graceful_tool_errors(request, handler):
       """Handle tool errors gracefully, returning informative messages."""
       try:
           return handler(request)
       except ConnectionError as e:
           return ToolMessage(
               content=f"Connection failed: {e}. I'll try a different approach.",
               tool_call_id=request.tool_call["id"]
           )
       except TimeoutError as e:
           return ToolMessage(
               content=f"Request timed out: {e}. The service may be slow.",
               tool_call_id=request.tool_call["id"]
           )
       except Exception as e:
           return ToolMessage(
               content=f"Tool error: {str(e)}. Let me try another approach.",
               tool_call_id=request.tool_call["id"]
           )
   ```

3. Add the error handler to the middleware list in `_handle_message_async`:
   ```python
   middleware=[
       graceful_tool_errors,  # First: catch and handle errors
       ToolRetryMiddleware(max_retries=2, backoff_factor=2.0),
       ModelCallLimitMiddleware(run_limit=10),
   ]
   ```

This ensures tool errors don't crash the agent - instead, informative error messages are returned to the model so it can adapt its approach.
  </action>
  <verify>
Python syntax check: `python -m py_compile plugins/langchain-agent/plugin.py`
Check error handler: `grep -n "graceful_tool_errors\|wrap_tool_call" plugins/langchain-agent/plugin.py`
  </verify>
  <done>
Custom `graceful_tool_errors` handler using `@wrap_tool_call` catches ConnectionError, TimeoutError, and general exceptions, returning informative ToolMessage responses
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **Syntax validation:**
   ```bash
   python -m py_compile plugins/langchain-agent/plugin.py
   ```

2. **Import validation:**
   ```bash
   cd plugins/langchain-agent && python -c "
   from langchain.agents import create_agent
   from langchain.agents.middleware import ToolRetryMiddleware, ModelCallLimitMiddleware, wrap_tool_call
   from langchain.messages import ToolMessage
   from langchain_anthropic import ChatAnthropic
   print('All imports resolve correctly')
   "
   ```

3. **Code inspection:**
   - `create_agent` is used (not `create_react_agent`) for agent creation
   - Middleware list includes ToolRetryMiddleware, ModelCallLimitMiddleware, and graceful_tool_errors
   - Anthropic model has `thinking` parameter configured
   - Error handler function exists and is decorated with `@wrap_tool_call`
</verification>

<success_criteria>
- [ ] `plugin.py` compiles without syntax errors
- [ ] All new imports resolve correctly
- [ ] Agent creation uses `create_agent` with middleware
- [ ] `ToolRetryMiddleware` configured with max_retries=2
- [ ] `ModelCallLimitMiddleware` configured with run_limit=10
- [ ] Anthropic model has extended thinking enabled (budget_tokens=2000)
- [ ] `graceful_tool_errors` handler catches and handles tool exceptions
- [ ] Existing functionality preserved (OpenAI bot, conversation history, fallback logic)
</success_criteria>

<output>
After completion, create `.planning/phases/18-agentic-loop/18-01-SUMMARY.md`
</output>
