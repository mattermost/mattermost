---
name: E2E Tests - Cypress Template
on:
  workflow_call:
    inputs:
      # Test configuration
      test_type:
        description: "Type of test run (smoke or full)"
        type: string
        required: true
      test_filter:
        description: "Test filter arguments"
        type: string
        required: true
      workers:
        description: "Number of parallel workers"
        type: number
        required: false
        default: 1
      timeout_minutes:
        description: "Job timeout in minutes"
        type: number
        required: false
        default: 30
      enabled_docker_services:
        description: "Space-separated list of docker services to enable"
        type: string
        required: false
        default: "postgres inbucket"

      # Common build variables
      commit_sha:
        type: string
        required: true
      branch:
        type: string
        required: true
      build_id:
        type: string
        required: true
      server_image:
        type: string
        required: true
      server:
        type: string
        required: false
        default: onprem

      # Reporting options
      enable_reporting:
        type: boolean
        required: false
        default: false
      report_type:
        type: string
        required: false
      pr_number:
        type: string
        required: false
      check_ad_cycle:
        description: "Check automation dashboard cycle for results"
        type: boolean
        required: false
        default: false

      # Commit status configuration
      context_name:
        description: "GitHub commit status context name"
        type: string
        required: true

    outputs:
      passed:
        description: "Number of passed tests"
        value: ${{ jobs.report.outputs.passed }}
      failed:
        description: "Number of failed tests"
        value: ${{ jobs.report.outputs.failed }}
      smoke_passed:
        description: "Whether smoke tests passed (for gating full tests)"
        value: ${{ jobs.report.outputs.smoke_passed }}
      status_check_url:
        description: "URL to test results"
        value: ${{ jobs.generate-test-cycle.outputs.status_check_url }}

    secrets:
      MM_LICENSE:
        required: false
      AUTOMATION_DASHBOARD_URL:
        required: false
      AUTOMATION_DASHBOARD_TOKEN:
        required: false
      PUSH_NOTIFICATION_SERVER:
        required: false
      REPORT_WEBHOOK_URL:
        required: false
      CWS_URL:
        required: false
      CWS_EXTRA_HTTP_HEADERS:
        required: false

jobs:
  update-initial-status:
    runs-on: ubuntu-24.04
    steps:
      - name: ci/set-initial-status
        uses: mattermost/actions/delivery/update-commit-status@f324ac89b05cc3511cb06e60642ac2fb829f0a63
        env:
          GITHUB_TOKEN: ${{ github.token }}
        with:
          repository_full_name: ${{ github.repository }}
          commit_sha: ${{ inputs.commit_sha }}
          context: ${{ inputs.context_name }}
          description: "Cypress ${{ inputs.test_type }} tests"
          status: pending

  generate-test-cycle:
    runs-on: ubuntu-24.04
    outputs:
      status_check_url: "${{ steps.generate-cycle.outputs.status_check_url }}"
      workers: "${{ steps.generate-workers.outputs.workers }}"
    steps:
      - name: ci/generate-workers
        id: generate-workers
        run: |
          echo "workers=$(jq -nc '[range(${{ inputs.workers }})]')" >> $GITHUB_OUTPUT

      - name: ci/checkout-repo
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ inputs.commit_sha }}
          fetch-depth: 0
      - name: ci/setup-node
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6.1.0
        with:
          node-version-file: ".nvmrc"
          cache: npm
          cache-dependency-path: "e2e-tests/cypress/package-lock.json"

      - name: ci/generate-test-cycle
        id: generate-cycle
        working-directory: e2e-tests
        env:
          AUTOMATION_DASHBOARD_URL: "${{ secrets.AUTOMATION_DASHBOARD_URL }}"
          AUTOMATION_DASHBOARD_TOKEN: "${{ secrets.AUTOMATION_DASHBOARD_TOKEN }}"
          BRANCH: "${{ inputs.branch }}-${{ inputs.test_type }}"
          BUILD_ID: "${{ inputs.build_id }}"
          TEST: cypress
          TEST_FILTER: "${{ inputs.test_filter }}"
        run: |
          set -e -o pipefail
          make generate-test-cycle | tee generate-test-cycle.out
          TEST_CYCLE_ID=$(sed -nE "s/^.*id: '([^']+)'.*$/\1/p" <generate-test-cycle.out)
          if [ -n "$TEST_CYCLE_ID" ]; then
            echo "status_check_url=https://automation-dashboard.vercel.app/cycles/${TEST_CYCLE_ID}" >> $GITHUB_OUTPUT
          else
            echo "status_check_url=${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" >> $GITHUB_OUTPUT
          fi

  run-tests:
    runs-on: ubuntu-24.04
    timeout-minutes: ${{ fromJSON(inputs.timeout_minutes) }}
    continue-on-error: ${{ inputs.workers > 1 }}
    needs:
      - generate-test-cycle
    if: needs.generate-test-cycle.result == 'success'
    strategy:
      fail-fast: false
      matrix:
        worker_index: ${{ fromJSON(needs.generate-test-cycle.outputs.workers) }}
    defaults:
      run:
        working-directory: e2e-tests
    env:
      AUTOMATION_DASHBOARD_URL: "${{ secrets.AUTOMATION_DASHBOARD_URL }}"
      AUTOMATION_DASHBOARD_TOKEN: "${{ secrets.AUTOMATION_DASHBOARD_TOKEN }}"
      SERVER: "${{ inputs.server }}"
      SERVER_IMAGE: "${{ inputs.server_image }}"
      MM_LICENSE: "${{ secrets.MM_LICENSE }}"
      ENABLED_DOCKER_SERVICES: "${{ inputs.enabled_docker_services }}"
      TEST: cypress
      TEST_FILTER: "${{ inputs.test_filter }}"
      BRANCH: "${{ inputs.branch }}-${{ inputs.test_type }}"
      BUILD_ID: "${{ inputs.build_id }}"
      CI_BASE_URL: "${{ inputs.test_type }}-test-${{ matrix.worker_index }}"
      CYPRESS_pushNotificationServer: "${{ secrets.PUSH_NOTIFICATION_SERVER }}"
      CWS_URL: "${{ secrets.CWS_URL }}"
      CWS_EXTRA_HTTP_HEADERS: "${{ secrets.CWS_EXTRA_HTTP_HEADERS }}"
    steps:
      - name: ci/checkout-repo
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ inputs.commit_sha }}
          fetch-depth: 0
      - name: ci/setup-node
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6.1.0
        with:
          node-version-file: ".nvmrc"
          cache: npm
          cache-dependency-path: "e2e-tests/cypress/package-lock.json"
      - name: ci/run-tests
        run: |
          make cloud-init
          make
      - name: ci/cloud-teardown
        if: always()
        run: make cloud-teardown
      - name: ci/upload-results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        if: always()
        with:
          name: cypress-${{ inputs.test_type }}-results-${{ matrix.worker_index }}
          path: |
            e2e-tests/cypress/logs/
            e2e-tests/cypress/results/
          retention-days: 5

  retest-failed:
    runs-on: ubuntu-24.04
    timeout-minutes: ${{ fromJSON(inputs.timeout_minutes) }}
    needs:
      - generate-test-cycle
      - run-tests
    if: always() && needs.generate-test-cycle.result == 'success' && needs.run-tests.result == 'failure'
    outputs:
      retest_passed: ${{ steps.check-retest.outputs.passed }}
    defaults:
      run:
        working-directory: e2e-tests
    env:
      AUTOMATION_DASHBOARD_URL: "${{ secrets.AUTOMATION_DASHBOARD_URL }}"
      AUTOMATION_DASHBOARD_TOKEN: "${{ secrets.AUTOMATION_DASHBOARD_TOKEN }}"
      SERVER: "${{ inputs.server }}"
      SERVER_IMAGE: "${{ inputs.server_image }}"
      MM_LICENSE: "${{ secrets.MM_LICENSE }}"
      ENABLED_DOCKER_SERVICES: "${{ inputs.enabled_docker_services }}"
      TEST: cypress
      BRANCH: "${{ inputs.branch }}-${{ inputs.test_type }}-retest"
      BUILD_ID: "${{ inputs.build_id }}-retest"
      CYPRESS_pushNotificationServer: "${{ secrets.PUSH_NOTIFICATION_SERVER }}"
      CWS_URL: "${{ secrets.CWS_URL }}"
      CWS_EXTRA_HTTP_HEADERS: "${{ secrets.CWS_EXTRA_HTTP_HEADERS }}"
    steps:
      - name: ci/checkout-repo
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ inputs.commit_sha }}
          fetch-depth: 0
      - name: ci/setup-node
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6.1.0
        with:
          node-version-file: ".nvmrc"
          cache: npm
          cache-dependency-path: "e2e-tests/cypress/package-lock.json"
      - name: ci/download-results
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        with:
          pattern: cypress-${{ inputs.test_type }}-results-*
          path: e2e-tests/cypress/
          merge-multiple: true
      - name: ci/extract-failed-tests
        id: failed-tests
        run: |
          # Extract failed spec files from mochawesome results
          FAILED_FILES=""
          for file in cypress/results/*.json; do
            if [ -f "$file" ]; then
              SPECS=$(jq -r '
                .results[]? |
                select(.suites[]?.tests[]?.state == "failed") |
                .file
              ' "$file" 2>/dev/null)
              FAILED_FILES="${FAILED_FILES} ${SPECS}"
            fi
          done
          FAILED_FILES=$(echo "$FAILED_FILES" | tr ' ' '\n' | grep -v '^$' | sort -u | tr '\n' ',' | sed 's/,$//')

          if [ -z "$FAILED_FILES" ]; then
            echo "No failed tests found"
            echo "has_failed=false" >> $GITHUB_OUTPUT
          else
            echo "Failed spec files: $FAILED_FILES"
            echo "has_failed=true" >> $GITHUB_OUTPUT
            echo "failed_files=$FAILED_FILES" >> $GITHUB_OUTPUT
          fi
      - name: ci/rerun-failed-tests
        if: steps.failed-tests.outputs.has_failed == 'true'
        env:
          FAILED_FILES: ${{ steps.failed-tests.outputs.failed_files }}
        run: |
          make cloud-init
          cd cypress
          npm ci
          npx cypress run --spec "$FAILED_FILES" || true
      - name: ci/cloud-teardown
        if: always()
        run: make cloud-teardown
      - name: ci/check-retest-results
        id: check-retest
        run: |
          if [ -f "cypress/results/summary.json" ]; then
            FAILED=$(jq '.failed // 0' cypress/results/summary.json)
            if [ "$FAILED" = "0" ]; then
              echo "passed=true" >> $GITHUB_OUTPUT
            else
              echo "passed=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "passed=false" >> $GITHUB_OUTPUT
          fi
      - name: ci/upload-retest-results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        if: always()
        with:
          name: cypress-${{ inputs.test_type }}-retest-results
          path: |
            e2e-tests/cypress/logs/
            e2e-tests/cypress/results/
          retention-days: 5

  report:
    runs-on: ubuntu-24.04
    needs:
      - generate-test-cycle
      - run-tests
      - retest-failed
    if: always() && needs.generate-test-cycle.result == 'success'
    outputs:
      passed: "${{ steps.calculate-results.outputs.passed }}"
      failed: "${{ steps.calculate-results.outputs.failed }}"
      smoke_passed: "${{ steps.calculate-results.outputs.smoke_passed }}"
      commit_status_message: "${{ steps.calculate-results.outputs.commit_status_message }}"
    defaults:
      run:
        working-directory: e2e-tests
    steps:
      - name: ci/checkout-repo
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: ${{ inputs.commit_sha }}
          fetch-depth: 0
      - name: ci/setup-node
        uses: actions/setup-node@395ad3262231945c25e8478fd5baf05154b1d79f # v6.1.0
        with:
          node-version-file: ".nvmrc"
          cache: npm
          cache-dependency-path: "e2e-tests/cypress/package-lock.json"
      - name: ci/download-results
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        with:
          pattern: cypress-${{ inputs.test_type }}-results-*
          path: e2e-tests/cypress/
          merge-multiple: true
      - name: ci/download-retest-results
        if: needs.retest-failed.result == 'success'
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        continue-on-error: true
        with:
          name: cypress-${{ inputs.test_type }}-retest-results
          path: e2e-tests/cypress/retest-results/
      - name: ci/merge-retest-results
        if: needs.retest-failed.result == 'success'
        run: |
          # If retest results exist and passed, use them for final status
          if [ -f "cypress/retest-results/results/summary.json" ]; then
            RETEST_FAILED=$(jq '.failed // 0' cypress/retest-results/results/summary.json 2>/dev/null || echo "1")
            ORIGINAL_FAILED=$(jq '.failed // 0' cypress/results/summary.json 2>/dev/null || echo "0")
            ORIGINAL_PASSED=$(jq '.passed // 0' cypress/results/summary.json 2>/dev/null || echo "0")

            if [ "$RETEST_FAILED" = "0" ]; then
              echo "Retest passed - updating results to show flaky tests"
              # Calculate flaky count (tests that failed initially but passed on retest)
              FLAKY_COUNT=$ORIGINAL_FAILED
              NEW_PASSED=$((ORIGINAL_PASSED + FLAKY_COUNT))
              # Update summary.json with flaky info
              jq --argjson passed "$NEW_PASSED" --argjson flaky "$FLAKY_COUNT" \
                '.passed = $passed | .failed = 0 | .flaky = $flaky' \
                cypress/results/summary.json > cypress/results/summary.json.tmp
              mv cypress/results/summary.json.tmp cypress/results/summary.json
            fi
          fi
      - name: ci/upload-combined-results
        if: inputs.workers > 1
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: cypress-${{ inputs.test_type }}-results
          path: |
            e2e-tests/cypress/logs/
            e2e-tests/cypress/results/
      - name: ci/publish-report
        if: inputs.enable_reporting
        env:
          TYPE: "${{ inputs.report_type }}"
          TEST: cypress
          SERVER: "${{ inputs.server }}"
          SERVER_IMAGE: "${{ inputs.server_image }}"
          AUTOMATION_DASHBOARD_URL: "${{ secrets.AUTOMATION_DASHBOARD_URL }}"
          WEBHOOK_URL: "${{ secrets.REPORT_WEBHOOK_URL }}"
          BRANCH: "${{ inputs.branch }}-${{ inputs.test_type }}"
          BUILD_ID: "${{ inputs.build_id }}"
          PR_NUMBER: "${{ inputs.pr_number }}"
        run: make report
      - name: ci/calculate-results
        id: calculate-results
        uses: ./.github/actions/calculate-e2e-test-results
        with:
          results_path: e2e-tests/cypress/results
          check_ad_cycle: "${{ inputs.check_ad_cycle }}"
      - name: ci/comment-failed-tests
        if: steps.calculate-results.outputs.failed != '0' && inputs.pr_number != ''
        env:
          GH_TOKEN: ${{ github.token }}
          PR_NUMBER: ${{ inputs.pr_number }}
          STATUS_CHECK_URL: ${{ needs.generate-test-cycle.outputs.status_check_url }}
          TEST_TYPE: ${{ inputs.test_type }}
          FAILED_COUNT: ${{ steps.calculate-results.outputs.failed }}
        run: |
          # Extract failed tests from mochawesome results
          FAILED_TESTS=""
          for file in cypress/results/*.json; do
            if [ -f "$file" ]; then
              TESTS=$(jq -r '
                .results[]?.suites[]?.tests[]? |
                select(.state == "failed") |
                "| `\(.title | gsub("`"; "\\`") | gsub("\\|"; "\\|"))` | `\(.file // "unknown")` |"
              ' "$file" 2>/dev/null)
              FAILED_TESTS="${FAILED_TESTS}${TESTS}"
            fi
          done

          # Count total and limit to 10 entries
          TOTAL_LINES=$(echo "$FAILED_TESTS" | grep -c '^|' || echo "0")
          FAILED_TESTS=$(echo "$FAILED_TESTS" | head -10)

          if [ -z "$FAILED_TESTS" ]; then
            FAILED_TESTS="| Unable to parse failed tests | - |"
          elif [ "$TOTAL_LINES" -gt 10 ]; then
            REMAINING=$((TOTAL_LINES - 10))
            FAILED_TESTS="${FAILED_TESTS}
          | _...and ${REMAINING} more failed tests_ | |"
          fi

          # Build comment body with collapsible section
          COMMENT_BODY=$(cat <<EOF
          ## E2E Test Failures

          <details>
          <summary>Cypress ${TEST_TYPE}: ${FAILED_COUNT} failed</summary>

          | Test | File |
          |------|------|
          ${FAILED_TESTS}

          </details>

          ---
          [View Full Report](${STATUS_CHECK_URL})
          EOF
          )

          # Check for existing comment and update, or create new
          EXISTING_COMMENT=$(gh api repos/${{ github.repository }}/issues/${PR_NUMBER}/comments \
            --jq '.[] | select(.body | startswith("## E2E Test Failures")) | .id' | head -1)

          if [ -n "$EXISTING_COMMENT" ]; then
            gh api repos/${{ github.repository }}/issues/comments/${EXISTING_COMMENT} \
              -X PATCH -f body="$COMMENT_BODY"
          else
            gh pr comment ${PR_NUMBER} --body "$COMMENT_BODY"
          fi
      - name: ci/assert-results
        run: |
          [ "${{ steps.calculate-results.outputs.failed }}" = "0" ]

  update-success-status:
    runs-on: ubuntu-24.04
    if: always() && needs.report.result == 'success' && needs.generate-test-cycle.result == 'success'
    needs:
      - generate-test-cycle
      - report
    steps:
      - uses: mattermost/actions/delivery/update-commit-status@f324ac89b05cc3511cb06e60642ac2fb829f0a63
        env:
          GITHUB_TOKEN: ${{ github.token }}
        with:
          repository_full_name: ${{ github.repository }}
          commit_sha: ${{ inputs.commit_sha }}
          context: ${{ inputs.context_name }}
          description: "${{ needs.report.outputs.commit_status_message || format('{0} tests passed ({1} passed)', inputs.test_type, needs.report.outputs.passed) }}"
          status: success
          target_url: ${{ needs.generate-test-cycle.outputs.status_check_url }}

  update-failure-status:
    runs-on: ubuntu-24.04
    if: always() && (needs.report.result != 'success' || needs.generate-test-cycle.result != 'success')
    needs:
      - generate-test-cycle
      - report
    steps:
      - uses: mattermost/actions/delivery/update-commit-status@f324ac89b05cc3511cb06e60642ac2fb829f0a63
        env:
          GITHUB_TOKEN: ${{ github.token }}
        with:
          repository_full_name: ${{ github.repository }}
          commit_sha: ${{ inputs.commit_sha }}
          context: ${{ inputs.context_name }}
          description: "${{ needs.report.outputs.commit_status_message || format('{0} tests failed ({1} failed)', inputs.test_type, needs.report.outputs.failed) }}"
          status: failure
          target_url: ${{ needs.generate-test-cycle.outputs.status_check_url }}
